{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Simulation\n",
    "`ldmunit` provides the functionality to simulate agents and interactive models against matching environments and store the generated data. This can be used for various purposes, two of which are model recovery and parameter recovery tasks which are the topic of the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Functionality\n",
    "Main simulation functions are `ldmunit.simulation.simulate` which is used for a single environment and single agent or model and `ldmunit.simulation.simulate_multienv_multimodel` which is used for many environments and a matching multi-subject model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulate documentation\n",
      "----------------------\n",
      "\n",
      "    Simulate the evolution of an environment and a model or an agent for a\n",
      "    fixed number of steps.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    env : :class:`gym.Env`\n",
      "        Environment.\n",
      "\n",
      "    model : :class:`ldmunit.models.LDMModel` and :class:`ldmunit.capabilities.Interactive` or :class:`ldmunit.models.LDMAgent`\n",
      "        Model or agent.\n",
      "\n",
      "    n_trials : int\n",
      "        Number of trials to perform. In each trial, model acts on the\n",
      "        last stimulus produced by the environment. Afterwards environment and\n",
      "        then the model is updated.\n",
      "\n",
      "    seed : int\n",
      "        Random seed used to initialize the environment.\n",
      "\n",
      "    check_env_model : bool\n",
      "        Whether to check if the model/agent and the environment has matching action and observation spaces.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    stimuli : list\n",
      "        List of all the stimuli produced after each trial. This list does not\n",
      "        contain the initial state of the environment. Hence, its size is `n_trials`.\n",
      "\n",
      "    rewards : list\n",
      "        List of rewards obtained after each trial.\n",
      "\n",
      "    actions : list\n",
      "        List of actions performed by the model in each trial.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from ldmunit.simulation import simulate\n",
    "print('simulate documentation')\n",
    "print('----------------------')\n",
    "print(simulate.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action and Observation Spaces\n",
    "In the function docstring you can see that simulate function performs checks to make sure that the given agent/model and the environment can be simulated together. The main requirement for this is that action and observation spaces of the environment and the agent/model must match. For example, `ldmunit.capabilities.DiscreteObservation` is a capability that requires a model to operate on discrete observation spaces. An environment that has `ldmunit.capabilities.DiscreteObservation` as its observation space can only be simulated against models/agents that operate on this observation space, as well.\n",
    "\n",
    "You can see the action and observation spaces of environments, agents and models in their superclass list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BanditEnv\n",
      "--------\n",
      "(<class 'ldmunit.capabilities.DiscreteAction'>, <class 'ldmunit.capabilities.DiscreteObservation'>, <class 'ldmunit.envs.base.LDMEnv'>)\n",
      "\n",
      "NWSLSModel\n",
      "--------\n",
      "(<class 'ldmunit.models.policy_model.PolicyModel'>, <class 'ldmunit.capabilities.DiscreteAction'>, <class 'ldmunit.capabilities.DiscreteObservation'>)\n",
      "\n",
      "NWSLSAgent\n",
      "--------\n",
      "(<class 'ldmunit.models.base.LDMAgent'>, <class 'ldmunit.capabilities.ProducesPolicy'>, <class 'ldmunit.capabilities.DiscreteAction'>, <class 'ldmunit.capabilities.DiscreteObservation'>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ldmunit.envs import BanditEnv\n",
    "from ldmunit.models.decision_making import NWSLSModel, NWSLSAgent\n",
    "\n",
    "for cls in (BanditEnv, NWSLSModel, NWSLSAgent):\n",
    "    print(cls.__name__)\n",
    "    print('--------')\n",
    "    print(cls.__bases__)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "Here we demonstrate the simulation results for a single model and an environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimuli: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Rewards: [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "Actions: [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "p_dist = [0.25, 0.25, 0.25, 0.25]\n",
    "n_action = len(p_dist)\n",
    "model = NWSLSModel(n_action=n_action, n_obs=1, seed=43)\n",
    "env = BanditEnv(p_dist=p_dist, seed=43)\n",
    "stimuli, rewards, actions = simulate(env, model, 15, seed=43)\n",
    "print('Stimuli:', stimuli)\n",
    "print('Rewards:', rewards)\n",
    "print('Actions:', actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ldmunit]",
   "language": "python",
   "name": "conda-env-ldmunit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
