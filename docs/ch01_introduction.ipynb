{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction to LDMUnit\n",
    "LDMUnit is a framework for test and validation of learning and decision making models. It is built mainly on top of [sciunit](https://github.com/scidash/sciunit) and [gym](https://github.com/openai/gym) libraries. It uses the same test-model-capability categorization first implemented in sciunit to run test suites consisting of several tests on a set of models. For a full list of features, please refer to README.md file or ldmunit documentation website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first example: Testing multiple models interactively\n",
    "As a toy example, we test three models interactively. Let us first import the models. ldmunit offers some single-subject model implementations. However, tests unify single- and multi-subject APIs by always working with multi-subject ones. We can effortlessly create multi-subject models from a single-subject implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to suppress sciunit config not found logs\n",
    "import sciunit\n",
    "import os\n",
    "sciunit.settings['CWD'] = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random respond, noisy-win-stay-lose-shift\n",
    "from ldmunit.models.decision_making import RandomRespondModel, NWSLSModel\n",
    "from ldmunit.models.utils import multi_from_single_interactive\n",
    "\n",
    "MultiRandomRespondModel = multi_from_single_interactive(RandomRespondModel)\n",
    "MultiNWSLSModel = multi_from_single_interactive(NWSLSModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ldmunit offers the `ldmunit.tests.InteractiveTest` base class for implementing interactive tests. This class requires the user to specify how the final score for a given model should be computed. In this example, we will use negative log-likelihood which is already provided by ldmunit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldmunit.tests import NLLTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need data to run the tests. In general, the type of data highly depends on the particular model. In this example, we assume that data is stored in `observations` variable. In later chapters, we will explain this part in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = {'stimuli': [], 'actions': [], 'rewards': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = NLLTest(name='Interactive negative log-likelihood test', observation=observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the models. All of the models we have imported in this tutorial operate on discrete action and discrete observation spaces. Therefore, we need to specify the dimension for these spaces. In addition, each model require certain parameters. Here we assume that parameters are already set beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim_action = 5\n",
    "ndim_observation = 8\n",
    "params_multi_rr = [{'bias': 0.5, 'action_bias': 4}] # some parameters\n",
    "multi_rr = MultiRandomRespondModel(params_multi_rr, n_action=ndim_action, n_obs=ndim_observation)\n",
    "\n",
    "params_multi_nwsls = [{'epsilon': 2}] #some parameters\n",
    "multi_nwsls = MultiNWSLSModel(params_multi_nwsls, n_action=ndim_action, n_obs=ndim_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the test on the list of models. Since we don't have any observations in this example, both scores are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Executing test <i>Interactive negative log-likelihood test</i> on model <i>RandomRespondModel</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Score is <a style=\"color: rgb(60,169,88)\">0</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Executing test <i>Interactive negative log-likelihood test</i> on model <i>NWSLSModel</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Score is <a style=\"color: rgb(60,169,88)\">0</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><div>\n",
       "<style scoped=\"\">\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" id=\"-7673578200600487666\">\n",
       "<thead>\n",
       "<tr style=\"text-align: right;\">\n",
       "<th></th>\n",
       "<th title=\"\n",
       "    Perform interactive test on models that produce a log pdf/pmf as their\n",
       "    predictions. Negative log-likelihood (NLL) function is used as the score.\n",
       "    \">Interactive negative log-likelihood</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<th title=\"Random respond model that predicts random actions for any kind of observation.\">RandomRespondModel</th>\n",
       "<td style=\"background-color: rgb(60,169,88);\" title=\"No description available\">0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th title=\"Noisy-win-stay-lose-shift model implementation.\">NWSLSModel</th>\n",
       "<td style=\"background-color: rgb(60,169,88);\" title=\"No description available\">0</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div></body></html>"
      ],
      "text/plain": [
       "                   Interactive negative log-likelihood test\n",
       "RandomRespondModel                                        0\n",
       "NWSLSModel                                                0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = [multi_rr, multi_nwsls]\n",
    "test.judge(model_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ldmunit]",
   "language": "python",
   "name": "conda-env-ldmunit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
