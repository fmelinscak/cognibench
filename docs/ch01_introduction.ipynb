{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction to LDMUnit\n",
    "LDMUnit is a framework for test and validation of learning and decision making models. It is built mainly on top of [sciunit](https://github.com/scidash/sciunit) and [gym](https://github.com/openai/gym) libraries. It uses the same test-model-capability categorization implemented in sciunit to run test suites consisting of several tests on a set of models. For a full list of features, please refer to README.md file or ldmunit documentation website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first example: Testing multiple models interactively\n",
    "As a toy example, we test three models interactively. Let us first import the models. ldmunit offers some single-subject model implementations. Tests can be used with single- or multi-subject models. In this section, we showcase testing multi-subject models and the automatic multi-subject creation from single-subject implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to suppress sciunit config not found logs\n",
    "import sciunit\n",
    "import os\n",
    "sciunit.settings['CWD'] = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldmunit.models.decision_making import RandomRespondModel, NWSLSModel\n",
    "from ldmunit.models.utils import multi_from_single_cls\n",
    "\n",
    "MultiRandomRespondModel = multi_from_single_cls(RandomRespondModel)\n",
    "MultiNWSLSModel = multi_from_single_cls(NWSLSModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need data to run the tests. In general, the type of data highly depends on the particular model. In this example, we assume that data is stored in `observations` variable. In later chapters, we will explain this part in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [{'stimuli': [], 'actions': [], 'rewards': []}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ldmunit offers the `ldmunit.testing.InteractiveTest` class for interactive tests. This class tests a given model using `(stimulus, action, reward)` tuples by passing each of these triples one at a time. Therefore, the model has the chance to update itself after seeing of these triples.\n",
    "\n",
    "`InteractiveTest` class requires the observations, the score type to use and in this case the boolean switch to signal that we are using multi-subject models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldmunit.testing import InteractiveTest\n",
    "from ldmunit.scores import NLLScore\n",
    "from ldmunit.utils import partialclass\n",
    "\n",
    "test = InteractiveTest(\n",
    "    name='Interactive negative log-likelihood test',\n",
    "    observation=observations,\n",
    "    score_type=partialclass(NLLScore, min_score=0, max_score=1e4),\n",
    "    multi_subject=True,\n",
    "    optimize_models=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the models. All of the models we have imported in this tutorial operate on discrete action and discrete observation spaces. Therefore, we need to specify the dimension for these spaces. In addition, each model require certain parameters. Here we assume that parameters are already set beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim_action = 5\n",
    "ndim_observation = 8\n",
    "num_subjects = 5\n",
    "\n",
    "multi_rr = MultiRandomRespondModel(n_subj=num_subjects, n_action=ndim_action, n_obs=ndim_observation)\n",
    "multi_nwsls = MultiNWSLSModel(n_subj=num_subjects, n_action=ndim_action, n_obs=ndim_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the test on the list of models. Since we don't have any observations in this example, both scores are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Executing test <i>Interactive negative log-likelihood test</i> on model <i>RandomRespondModel</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Score is <a style=\"color: rgb(230,78,52)\">0</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Executing test <i>Interactive negative log-likelihood test</i> on model <i>NWSLSModel</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Score is <a style=\"color: rgb(230,78,52)\">0</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><div>\n",
       "<style scoped=\"\">\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" id=\"-8203712375593940035\">\n",
       "<thead>\n",
       "<tr style=\"text-align: right;\">\n",
       "<th></th>\n",
       "<th title=\"\n",
       "    Perform interactive tests by feeding the input samples (stimuli, rewards, actions) one at a time and updating the\n",
       "    model after each sample with the corresponding reward.\n",
       "    \">Interactive negative log-likelihood</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<th title=\"Random respond model implementation.\">RandomRespondModel</th>\n",
       "<td style=\"background-color: rgb(230,78,52);\" title=\"No description available\">0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th title=\"Noisy-win-stay-lose-shift model implementation.\">NWSLSModel</th>\n",
       "<td style=\"background-color: rgb(230,78,52);\" title=\"No description available\">0</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div></body></html>"
      ],
      "text/plain": [
       "                   Interactive negative log-likelihood test\n",
       "RandomRespondModel                                        0\n",
       "NWSLSModel                                                0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_suite = sciunit.TestSuite([test], name='Test suite')\n",
    "model_list = [multi_rr, multi_nwsls]\n",
    "test_suite.judge(model_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ldmunit]",
   "language": "python",
   "name": "conda-env-ldmunit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
