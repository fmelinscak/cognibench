{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import sciunit\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ldmunit.models import decision_making, associative_learning\n",
    "from src.ldmunit.models.utils import loglike, train_with_obs, simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bandit import BanditEnv, BanditAssociateEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = 2\n",
    "n_obs = 3\n",
    "n_trials = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for random responding\n",
      "The log-likelihood:    -43.109\n",
      "[0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing for random responding\")\n",
    "paras = {'bias': 0.8, 'action_bias': 1}\n",
    "\n",
    "model = decision_making.RandomRespondModel(n_actions, n_obs, paras)\n",
    "env = BanditEnv([0.3, 0.7], [1,1])\n",
    "stimuli, rewards, actions = simulate(env, model, n_trials)\n",
    "a = loglike(model, stimuli, rewards, actions)\n",
    "print(\"The log-likelihood: {:10.5}\".format(a))\n",
    "\n",
    "opt = train_with_obs(model, stimuli, rewards, actions)\n",
    "if opt.success:\n",
    "    print(opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for noisy-win-stay-lose-shift\n",
      "The log-likelihood:    -71.538\n",
      "[0.8]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing for noisy-win-stay-lose-shift\")\n",
    "paras = {'epsilon': 0.8}\n",
    "\n",
    "model = decision_making.NWSLSModel(n_actions, n_obs, paras)\n",
    "env = BanditEnv([0.3, 0.7], [1,1])\n",
    "stimuli, rewards, actions = simulate(env, model, n_trials)\n",
    "a = loglike(model, stimuli, rewards, actions)\n",
    "print(\"The log-likelihood: {:10.5}\".format(a))\n",
    "\n",
    "opt = train_with_obs(model, stimuli, rewards, actions)\n",
    "if opt.success:\n",
    "    print(opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for RWCK\n",
      "The log-likelihood:     -72.59\n",
      "[0.1 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing for RWCK\")\n",
    "paras = {'w0': 0.1, 'alpha': 0.5, 'alpha_c': 0.5, 'beta': 0.5, 'beta_c': 0.5}\n",
    "\n",
    "model = decision_making.RWCKModel(n_actions, n_obs, paras)\n",
    "env = BanditEnv([0.3, 0.7], [1,1])\n",
    "stimuli, rewards, actions = simulate(env, model, n_trials)\n",
    "a = loglike(model, stimuli, rewards, actions)\n",
    "print(\"The log-likelihood: {:10.5}\".format(a))\n",
    "\n",
    "opt = train_with_obs(model, stimuli, rewards, actions)\n",
    "if opt.success:\n",
    "    print(opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ldmunit.capabilities import Interactive\n",
    "\n",
    "class MultiMeta(type):\n",
    "    def __new__(cls, name, bases, dct):\n",
    "        single_cls = dct['single_cls']\n",
    "        base_classes = (single_cls.__bases__)\n",
    "        out_cls = super().__new__(cls, name, base_classes, dct)\n",
    "\n",
    "        def multi_init(self, param_list, *args, **kwargs):\n",
    "            self.models = []\n",
    "            for param in param_list:\n",
    "                self.models.append(single_cls(*args, **kwargs))\n",
    "        out_cls.__init__ = multi_init\n",
    "\n",
    "        def multi_predict(self, idx, *args, **kwargs):\n",
    "            return self.models[idx].predict(*args, **kwargs)\n",
    "        out_cls.predict = multi_predict\n",
    "\n",
    "        def multi_reset(self, idx, *args, **kwargs):\n",
    "            return self.models[idx].reset(*args, **kwargs)\n",
    "        out_cls.reset = multi_reset\n",
    "        \n",
    "        def multi_update(self, idx, *args, **kwargs):\n",
    "            return self.models[idx].update(*args, **kwargs)\n",
    "        out_cls.update = multi_update\n",
    "        \n",
    "        def multi_act(self, idx, *args, **kwargs):\n",
    "            return self.models[idx].act(*args, **kwargs)\n",
    "        out_cls.act = multi_act\n",
    "\n",
    "        return out_cls\n",
    "\n",
    "def multi_from_single(single_cls, multi_cls_name):\n",
    "    return MultiMeta(multi_cls_name, (), {'single_cls': single_cls})\n",
    "\n",
    "\n",
    "param_list = [{'epsilon': 0.5}] * 10\n",
    "MultiA = multi_from_single(decision_making.NWSLSModel, 'MultiNWSLS')\n",
    "mA = MultiA(param_list=range(10), n_actions=5, n_obs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 3\n",
    "n_trials = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for RwNormModel\n",
      "The log-likelihood:    -91.849\n",
      "[0.1 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing for RwNormModel\")\n",
    "paras = {'w0': 0.1, 'alpha': 0.5, 'sigma': 0.5, 'b0': 0.5, 'b1': 0.5}\n",
    "\n",
    "model = associative_learning.RwNormModel(n_obs, paras)\n",
    "env = BanditAssociateEnv([0.3, 0.7, 0.8], [1,1])\n",
    "stimuli, rewards, actions = simulate(env, model, n_trials)\n",
    "a = loglike(model, stimuli, rewards, actions)\n",
    "print(\"The log-likelihood: {:10.5}\".format(a))\n",
    "\n",
    "opt = train_with_obs(model, stimuli, rewards, actions)\n",
    "if opt.success:\n",
    "    print(opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for KrwNormModel\n",
      "The log-likelihood:    -142.21\n",
      "[0.1  0.5  0.5  0.5  0.5  0.23 0.32 0.34]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing for KrwNormModel\")\n",
    "paras = {'w0': 0.1, 'alpha': 0.5, 'sigma': 0.5, 'b0': 0.5, 'b1': 0.5, 'logSigmaWInit': 0.23, 'logTauSq': 0.32,\n",
    "        'logSigmaRSq': 0.34}\n",
    "\n",
    "model = associative_learning.KrwNormModel(n_obs, paras)\n",
    "env = BanditAssociateEnv([0.3, 0.7, 0.8], [1,1])\n",
    "stimuli, rewards, actions = simulate(env, model, n_trials)\n",
    "a = loglike(model, stimuli, rewards, actions)\n",
    "print(\"The log-likelihood: {:10.5}\".format(a))\n",
    "\n",
    "opt = train_with_obs(model, stimuli, rewards, actions)\n",
    "if opt.success:\n",
    "    print(opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for lsspd\n",
      "The log-likelihood:    -52.967\n",
      "[0.1  0.5  0.5  0.5  0.5  0.23 0.32 0.34]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing for lsspd\")\n",
    "paras = {'w0': 0.1, 'alpha': 0.5, 'sigma': 0.5, 'b0': 0.5, 'b1': 0.5, 'eta': 0.23, 'kappa': 0.32,\n",
    "        'mix_coef': 0.34}\n",
    "\n",
    "model = associative_learning.LSSPDModel(n_obs, paras)\n",
    "env = BanditAssociateEnv([0.3, 0.7, 0.8], [1,1])\n",
    "stimuli, rewards, actions = simulate(env, model, n_trials)\n",
    "a = loglike(model, stimuli, rewards, actions)\n",
    "print(\"The log-likelihood: {:10.5}\".format(a))\n",
    "\n",
    "opt = train_with_obs(model, stimuli, rewards, actions)\n",
    "if opt.success:\n",
    "    print(opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for beta binomial\n",
      "The log-likelihood:       -inf\n",
      "[0.5  0.5  0.34]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing for beta binomial\")\n",
    "paras = {'b0': 0.5, 'b1': 0.5, 'mix_coef': 0.34}\n",
    "\n",
    "model = associative_learning.BetaBinomialModel(n_obs, paras)\n",
    "env = BanditAssociateEnv([0.3, 0.7, 0.8], [1,1])\n",
    "stimuli, rewards, actions = simulate(env, model, n_trials)\n",
    "a = loglike(model, stimuli, rewards, actions)\n",
    "print(\"The log-likelihood: {:10.5}\".format(a))\n",
    "\n",
    "opt = train_with_obs(model, stimuli, rewards, actions)\n",
    "if opt.success:\n",
    "    print(opt.x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
