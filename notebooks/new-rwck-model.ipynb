{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import sciunit\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gym.spaces.discrete.Discrete"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaces.Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "class A():\n",
    "    a = 123\n",
    "    \n",
    "    def print_a(self):\n",
    "        print(A.a)\n",
    "        \n",
    "    def touch_a(self):\n",
    "        A.a = 124\n",
    "\n",
    "\n",
    "test=A()\n",
    "test.a\n",
    "test.touch_a()\n",
    "test.print_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = spaces.MultiBinary(3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ldmunit.models.RWCK import RWCKModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bandit import BanditTwoArmedHighLowFixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = dict(zip(['alpha', 'alpha_c', 'beta', 'beta_c', 'w0'], [1,1,1,1,0]))\n",
    "model = RWCKModel(2, 1, paras= paras)\n",
    "env = BanditTwoArmedHighLowFixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(env, model, n_trials, seed=0):\n",
    "    \"\"\"Simulation in a given AI Gym environment.\"\"\"\n",
    "    #TODO: add support for env.seed()\n",
    "    assert isinstance(env, gym.Env)\n",
    "    assert isinstance(model, sciunit.Model)\n",
    "    assert isinstance(n_trials, int)\n",
    "    \n",
    "    assert model.paras != None #TODO: add assert for keys\n",
    "\n",
    "\n",
    "    # reset the agent state and \n",
    "    model.reset()\n",
    "    init_stimulus = env._reset()\n",
    "\n",
    "    a = np.zeros(n_trials, dtype=int) #TODO: change dtype\n",
    "    r = np.zeros(n_trials, dtype=int)\n",
    "    s = np.zeros(n_trials, dtype=int)\n",
    "\n",
    "    # add the first stimulus in the environment\n",
    "    s = np.insert(s, 0, init_stimulus, axis=0)\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        # compute choice probabilities\n",
    "        P = model.predict(s[i])\n",
    "\n",
    "        # action based on choice probabilities\n",
    "        a[i] = model.act(P)\n",
    "\n",
    "        # generate reward based on action\n",
    "        s[i+1], r[i], done, _ = env._step(a[i])\n",
    "\n",
    "        # update choice kernel and Q weights\n",
    "        model.update(s[i], r[i], a[i], done)\n",
    "\n",
    "    # delete the extra stimulus\n",
    "    s = np.delete(s, n_trials, axis=0)\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    obs = {\n",
    "        'stimuli': s,\n",
    "        'actions': a,\n",
    "        'rewards': r,\n",
    "    }\n",
    "\n",
    "    return obs\n",
    "\n",
    "def simulate_multi(env, model, n_trials, seed=0):\n",
    "    \"\"\"Simulation in a given AI Gym environment.\"\"\"\n",
    "    #TODO: add support for env.seed()\n",
    "    assert isinstance(env, gym.Env)\n",
    "    assert isinstance(model, sciunit.Model)\n",
    "    assert isinstance(n_trials, int)\n",
    "    \n",
    "    assert model.paras != None #TODO: add assert for keys\n",
    "    \n",
    "    model.reset()\n",
    "    actions, stimuli, rewards = [], [], []\n",
    "    \n",
    "    for j in range(model.n_sub):\n",
    "        # reset the agent state and \n",
    "        init_stimulus = env._reset()\n",
    "\n",
    "        a = np.zeros(n_trials, dtype=int) #TODO: change dtype\n",
    "        r = np.zeros(n_trials, dtype=int)\n",
    "        s = np.zeros(n_trials, dtype=int)\n",
    "\n",
    "        # add the first stimulus in the environment\n",
    "        s = np.insert(s, 0, init_stimulus, axis=0)\n",
    "    \n",
    "        for i in range(n_trials):\n",
    "            # compute choice probabilities\n",
    "            P = model.predict(s[i], j)\n",
    "\n",
    "            # action based on choice probabilities\n",
    "            a[i] = model.act(P)\n",
    "\n",
    "            # generate reward based on action\n",
    "            s[i+1], r[i], done, _ = env._step(a[i])\n",
    "\n",
    "            # update choice kernel and Q weights\n",
    "            model.update(s[i], r[i], a[i], done, j)\n",
    "\n",
    "        # delete the extra stimulus\n",
    "        s = np.delete(s, n_trials, axis=0)\n",
    "        \n",
    "        actions.append(a)\n",
    "        stimuli.append(s)\n",
    "        rewards.append(r)\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    obs = {\n",
    "        'stimuli': stimuli,\n",
    "        'actions': actions,\n",
    "        'rewards': rewards,\n",
    "    }\n",
    "\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike(model, stimuli, rewards, actions):\n",
    "    #TODO: add assertion for the length\n",
    "    n_trials = len(stimuli)\n",
    "    \n",
    "    res = 0\n",
    "    \n",
    "    # reset the model's state\n",
    "    model.reset()\n",
    "    done = False\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        # compute choice probabilities\n",
    "        P = model.predict(stimuli[i])\n",
    "        \n",
    "        # probability of the action\n",
    "        #TODO: generalize this\n",
    "        p = model.loglikelihood(P, actions[i])\n",
    "\n",
    "        # add log-likelihood\n",
    "        res += np.log(p)\n",
    "        # update choice kernel and Q weights\n",
    "        model.update(stimuli[i], rewards[i], actions[i], done)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, stimuli, rewards, actions, fixed):\n",
    "    \n",
    "    vals = list(fixed.values())\n",
    "\n",
    "    def objective_fun(vals):\n",
    "        for k, v in zip(fixed.keys(), vals):\n",
    "            model.paras[k] = v\n",
    "        return -loglike(model, stimuli, rewards, actions)\n",
    "\n",
    "    opt_results = scipy.optimize.minimize(fun=objective_fun,\n",
    "                                          x0=vals, \n",
    "                                          bounds=[(0,1000)]*len(vals))\n",
    "    if opt_results.success:\n",
    "        for k, v in zip(fixed.keys(), opt_results.x):\n",
    "            model.paras[k] = v\n",
    "    return opt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = simulate(env, model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likehood value -42.59922642295281\n"
     ]
    }
   ],
   "source": [
    "a = loglike(model, res['stimuli'], res['rewards'], res['actions'])\n",
    "print(\"Log-likehood value\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paras before minimize {'alpha': 1, 'alpha_c': 1, 'beta': 1, 'beta_c': 1, 'w0': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"paras before minimize\", model.paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = dict(zip(['beta_c'], [1]))\n",
    "opt = fit(model, res['stimuli'], res['rewards'], res['actions'], fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paras after minimize {'alpha': 1, 'alpha_c': 1, 'beta': 1, 'beta_c': 2.258099102131004, 'w0': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"paras after minimize\", model.paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ldmunit.models.RWCK import RWCKMultiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = RWCKMultiModel(2, 1, paras=[paras]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stimuli': [array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       " 'actions': [array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "         0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])],\n",
       " 'rewards': [array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "         1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "         1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "         1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1])]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_multi(env, multi_model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ldmunit.models.nwsls import NWSLSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = NWSLSModel(2,1, dict(epsilon=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stimuli': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'actions': array([1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]),\n",
       " 'rewards': array([0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate(env, nw, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ldmunit.models.nwsls import NWSLSMultiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_nw = NWSLSMultiModel(2,1, [dict(epsilon=0.5)]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stimuli': [array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       " 'actions': [array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "         0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "         1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "         0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1])],\n",
       " 'rewards': [array([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "         0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0]),\n",
       "  array([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "         1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0])]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_multi(env, multi_nw, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likehood value -57.73759185865701\n"
     ]
    }
   ],
   "source": [
    "a = loglike(nw, res['stimuli'], res['rewards'], res['actions'])\n",
    "print(\"Log-likehood value\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likehood value -40.29928461375536\n"
     ]
    }
   ],
   "source": [
    "a = loglike(model, res['stimuli'], res['rewards'], res['actions'])\n",
    "print(\"Log-likehood value\", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
