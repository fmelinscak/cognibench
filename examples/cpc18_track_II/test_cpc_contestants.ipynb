{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from ldmunit.testing import BatchTrainAndTest\n",
    "import ldmunit.scores as scores\n",
    "from ldmunit.utils import partialclass\n",
    "from ldmunit.models import CACO\n",
    "from ldmunit.capabilities import Interactive\n",
    "from sciunit import TestSuite\n",
    "from sciunit import settings as sciunit_settings\n",
    "\n",
    "from model_defs import PythonModel, RModel\n",
    "\n",
    "sciunit_settings[\"CWD\"] = getcwd()\n",
    "\n",
    "\n",
    "def get_models(model_IDs, folder_name_fmt, model_name_fmt, model_ctor):\n",
    "    models = []\n",
    "    for model_id in model_IDs:\n",
    "        folder_name = folder_name_fmt.format(model_id)\n",
    "        model_name = model_name_fmt.format(model_id)\n",
    "        models.append(model_ctor(import_base_path=folder_name, name=model_name))\n",
    "    return models\n",
    "\n",
    "\n",
    "# Transform outputs to be consistent with maximization (i.e., not minimization)\n",
    "def pBpMaxTransform(orig_vec, is_b_max):\n",
    "    orig_vec.name = \"B\"\n",
    "    new_vec = pd.concat([orig_vec, is_b_max], axis=1)\n",
    "    new_vec.loc[new_vec[\"isBMax\"] == False, \"B\"] = 1 - new_vec[\"B\"]\n",
    "    return new_vec[\"B\"]\n",
    "\n",
    "\n",
    "def getSplit(dd, seed=1, nSubjTest=30, nGamesPerSubjTest=5):\n",
    "\n",
    "    if \"SubjID\" not in dd.columns or \"GameID\" not in dd.columns:\n",
    "        print(\"data must include SubjID and GameID columns\")\n",
    "        return None, None\n",
    "\n",
    "    dd = dd.sort_values(by=['SubjID', 'GameID'])\n",
    "    np.random.seed(seed)\n",
    "    subjs = np.array(list(dd['SubjID'].unique()))\n",
    "    subj2remove = np.random.choice(subjs, nSubjTest, replace=False)\n",
    "    train = np.ones(dd.shape[0], dtype=np.bool)\n",
    "    test = np.zeros(dd.shape[0], dtype=np.bool)\n",
    "    for s in range(0, nSubjTest):\n",
    "        subjD = dd.loc[dd['SubjID'] == subj2remove[s]]\n",
    "        games = np.array(list(subjD['GameID'].unique()))\n",
    "        games2remove = np.random.choice(games, nGamesPerSubjTest, replace=False)\n",
    "        for g in range(0, nGamesPerSubjTest):\n",
    "            mask = (dd['SubjID'] == subj2remove[s]) & (dd['GameID'] == games2remove[g])\n",
    "            test |= mask\n",
    "            train &= ~mask\n",
    "    train_idx = np.where(train)[0]\n",
    "    test_idx = np.where(test)[0]\n",
    "    return train_idx, test_idx\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # prepare data\n",
    "    df = pd.read_csv(\"individualBlockAvgs.csv\")\n",
    "    df = df.drop(columns='BEAST_blkPred')\n",
    "\n",
    "    is_b_max = df[\"diffEV\"] >= 0\n",
    "    is_b_max.name = \"isBMax\"\n",
    "    df[\"B\"] = pBpMaxTransform(df[\"B\"], is_b_max)\n",
    "\n",
    "    first_part = df.loc[df.SubjID < 60000]\n",
    "    second_part = df.loc[df.SubjID >= 60000]\n",
    "    train_indices, test_indices = getSplit(second_part, seed=1)\n",
    "    train_indices += first_part.shape[0]\n",
    "    test_indices += first_part.shape[0]\n",
    "    train_indices = np.concatenate((np.arange(first_part.shape[0], dtype=np.int64), train_indices))\n",
    "\n",
    "    stimuli = df.values[:, :-1]\n",
    "    actions = df.values[:, -1].astype(np.float64)\n",
    "    obs_dict = {\"stimuli\": stimuli, \"actions\": actions}\n",
    "\n",
    "    # prepare models\n",
    "    python_model_IDs = [0]\n",
    "    #r_model_IDs = [1, 2]\n",
    "    r_model_IDs = []\n",
    "    models = get_models(python_model_IDs, 'contestant_{}', 'Contestant {} (Python)', PythonModel) + get_models(r_model_IDs, 'contestant_{}', 'Contestant {} (R)', RModel)\n",
    "\n",
    "    # prepare tests\n",
    "    MSEScore = partialclass(scores.MSEScore, min_score=0, max_score=1)\n",
    "    MAEScore = partialclass(scores.MAEScore, min_score=0, max_score=1)\n",
    "    CrossEntropyScore = partialclass(scores.CrossEntropyScore, min_score=0, max_score=1000)\n",
    "    PearsonCorrScore = partialclass(scores.PearsonCorrelationScore, min_score=-1, max_score=1)\n",
    "    suite = TestSuite(\n",
    "        [\n",
    "            BatchTrainAndTest(name=\"MSE Test\", observation=obs_dict, score_type=MSEScore),\n",
    "            BatchTrainAndTest(name=\"MAE Test\", observation=obs_dict, score_type=MAEScore),\n",
    "            BatchTrainAndTest(name=\"Cross Entropy Test\", observation=obs_dict, score_type=CrossEntropyScore),\n",
    "            BatchTrainAndTest(name=\"Pearson Correlation Test\", observation=obs_dict, score_type=PearsonCorrScore),\n",
    "        ],\n",
    "        name=\"Batch test suite\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Executing test <i>MSE Test</i> on model <i>Contestant 0 (Python)</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Score is <a style=\"color: rgb(122,198,101)\">0.118</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Executing test <i>MAE Test</i> on model <i>Contestant 0 (Python)</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Score is <a style=\"color: rgb(187,226,120)\">0.275</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Executing test <i>Cross Entropy Test</i> on model <i>Contestant 0 (Python)</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Score is <a style=\"color: rgb(63,170,89)\">0.327</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Executing test <i>Pearson Correlation Test</i> on model <i>Contestant 0 (Python)</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Score is <a style=\"color: rgb(223,242,147)\">0.235</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html><body><div>\n",
       "<style scoped=\"\">\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" id=\"8815115443450585579\">\n",
       "<thead>\n",
       "<tr style=\"text-align: right;\">\n",
       "<th></th>\n",
       "<th title>MSE Test</th>\n",
       "<th title>MAE Test</th>\n",
       "<th title>Cross Entropy Test</th>\n",
       "<th title>Pearson Correlation Test</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<th title=\"No description available\">Contestant 0 (Python)</th>\n",
       "<td style=\"background-color: rgb(122,198,101);\" title=\"No description available\">0.118</td>\n",
       "<td style=\"background-color: rgb(187,226,120);\" title=\"No description available\">0.275</td>\n",
       "<td style=\"background-color: rgb(63,170,89);\" title=\"No description available\">0.327</td>\n",
       "<td style=\"background-color: rgb(223,242,147);\" title=\"No description available\">0.235</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div></body></html>"
      ],
      "text/plain": [
       "                      MSE Test MAE Test Cross Entropy Test  \\\n",
       "Contestant 0 (Python)    0.118    0.275              0.327   \n",
       "\n",
       "                      Pearson Correlation Test  \n",
       "Contestant 0 (Python)                    0.235  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    suite.judge(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ldmunit]",
   "language": "python",
   "name": "conda-env-ldmunit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
